
# FGMFN: Fine-Grained Multiscale Cross-Modal Sentiment Analysis

This project predicts sentiment in advertisements by analyzing both **images** and **text**.

---

## üìÇ Folder & File Overview

Below is a description of each file and folder, along with example usage.

---

### 1. `data/` ‚Äî Datasets
- **ytb_ads/** ‚Äî YouTube Ads dataset  
- **twitter2015/** ‚Äî Twitter dataset (2015)  
- **twitter2017/** ‚Äî Twitter dataset (2017)  

**Example dataset format (`train.txt`):**

images/ad1.jpg	This product is amazing!	2 images/ad2.jpg	Not worth the money.	0

- First column: image path  
- Second column: ad text  
- Third column: sentiment label (0 = negative, 1 = neutral, 2 = positive)  

---

### 2. `models/` ‚Äî Model Components

#### `fg_mfn.py` ‚Äî Core FGMFN model combining image & text features
```python
from models.fg_mfn import FGMFN
model = FGMFN(embed_dim=256)

visual_module.py ‚Äî Multi-scale image feature extractor
from models.visual_module import VisualFeatureExtractor
visual_model = VisualFeatureExtractor()

text_module.py ‚Äî Text encoder with visual guidance
from models.text_module import TextEncoder
text_model = TextEncoder(model_name="bert-base-uncased")

3. losses/ ‚Äî Custom Loss Functions
matching_loss.py ‚Äî Matches image & text features if they belong together
from losses.matching_loss import MatchingLoss
loss_fn = MatchingLoss(margin=0.2)

mutual_info_loss.py ‚Äî Encourages information sharing between image & text
from losses.mutual_info_loss import MutualInfoLoss
loss_fn = MutualInfoLoss()

4. training/ ‚Äî Training & Evaluation
train.py ‚Äî Trains the FGMFN model
python training/train.py --config configs/default.yaml

evaluate.py ‚Äî Tests the trained model
python training/evaluate.py --config configs/default.yaml

5. utils/ ‚Äî Helper Functions
dataset.py ‚Äî Loads image + text dataset into PyTorch
from utils.dataset import AdvertisementDataset
dataset = AdvertisementDataset("data/ytb_ads", split="train")

preprocessing.py ‚Äî Cleans and preprocesses text
from utils.preprocessing import clean_text
print(clean_text("This Product!!! is Awesome..."))  # 'this product is awesome'

metrics.py ‚Äî Calculates evaluation metrics
from utils.metrics import compute_accuracy
acc = compute_accuracy(pred_logits, true_labels)

6. configs/ ‚Äî Project Configurations
default.yaml ‚Äî Controls dataset paths, training settings, and model parameters
training:
  epochs: 10
  batch_size: 32
model:
  embed_dim: 256

7. Root Files
 * requirements.txt ‚Äî Python dependencies
 * README.md ‚Äî Documentation (this file)
üöÄ How to Run the Project
1Ô∏è‚É£ Install dependencies
pip install -r requirements.txt

2Ô∏è‚É£ Train the model
python training/train.py --config configs/default.yaml

3Ô∏è‚É£ Evaluate the model
python training/evaluate.py --config configs/default.yaml

If this isn't what you meant, could you clarify what you mean by "don't appear neatly in md"?
